# PG-107: Enhanced HTML Scraping Implementation
# This patch enhances the fetch_html_fallback method to use the discovered API endpoint

# Apply this patch to odds_provider/prizepicks.py

# Find and replace the existing fetch_html_fallback method (lines ~161-234) with:

def fetch_html_fallback(self, league: str = "NBA") -> List[Dict[str, Any]]:
    """
    Enhanced fallback method that tries multiple approaches:
    1. Direct API endpoint (discovered during HTML analysis)
    2. BeautifulSoup HTML scraping (original method)
    3. Return empty list if all fail
    
    Args:
        league: Sport league (NBA, NFL, etc.)
        
    Returns:
        List of scraped projections
    """
    logger.warning(f"Using enhanced HTML fallback for {league} projections")
    
    # Get league ID
    league_id = self.LEAGUE_IDS.get(league.upper())
    if not league_id:
        logger.error(f"Unknown league: {league}")
        return []
    
    # Method 1: Try the partner API endpoint directly
    api_url = f"https://partner-api.prizepicks.com/projections?league_id={league_id}"
    
    try:
        self._rate_limit()
        
        response = self.session.get(api_url, timeout=30)
        
        if response.status_code == 200:
            data = response.json()
            
            # Use the existing parse_projections_to_slips method
            slips = self.parse_projections_to_slips(data)
            
            if slips:
                logger.info(f"HTML fallback (API method) fetched {len(slips)} projections")
                return slips
            else:
                logger.warning("API returned empty projections, trying HTML scraping...")
                
        elif response.status_code == 403:
            logger.warning("Got 403 from API endpoint, trying HTML scraping...")
        else:
            logger.warning(f"API endpoint returned status {response.status_code}")
            
    except Exception as e:
        logger.error(f"API endpoint method failed: {e}")
    
    # Method 2: Original HTML scraping with BeautifulSoup
    logger.info("Falling back to BeautifulSoup HTML scraping...")
    
    self._rate_limit()
    
    # Map league to URL path
    league_paths = {
        "NBA": "nba",
        "NFL": "nfl",
        "MLB": "mlb", 
        "NHL": "nhl",
        "WNBA": "wnba",
        "NCAAF": "ncaaf",
        "NCAAB": "ncaab"
    }
    
    league_path = league_paths.get(league.upper(), "nba")
    url = f"{self.WEB_URL}/{league_path}"
    
    try:
        response = self.session.get(url, timeout=30)
        
        if response.status_code != 200:
            logger.error(f"Failed to fetch HTML: {response.status_code}")
            return []
            
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # Try to find projections in the page
        projections = []
        
        # Look for React state data
        script_tags = soup.find_all('script')
        for script in script_tags:
            if script.string and ('window.__INITIAL_STATE__' in script.string or 
                                  'window.initialData' in script.string):
                try:
                    # Extract JSON from script
                    match = re.search(r'=\s*({.*?});', script.string, re.DOTALL)
                    if match:
                        state_data = json.loads(match.group(1))
                        projections = self._extract_projections_from_state(state_data)
                        if projections:
                            logger.info(f"Extracted {len(projections)} projections from React state")
                            return projections
                except Exception as e:
                    logger.warning(f"Failed to parse React state: {e}")
        
        # Try to find projection cards directly
        projection_cards = soup.find_all(['div', 'article'], class_=re.compile(r'projection|player-prop|card'))
        
        for card in projection_cards:
            try:
                projection = self._parse_projection_card(card)
                if projection:
                    projections.append(projection)
            except Exception as e:
                logger.warning(f"Failed to parse projection card: {e}")
        
        logger.info(f"Scraped {len(projections)} projections from HTML")
        return projections
        
    except Exception as e:
        logger.error(f"HTML scraping failed: {e}")
        return []
